"""
Agentic Analysis - Advanced AI Reasoning
=========================================
Experimental agentic AI engine with plan-execute-reflect capabilities.
"""

import streamlit as st
import sys
from pathlib import Path
from datetime import datetime
import json

# Add frontend directory to path
frontend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(frontend_dir))

from components.auth_utils import require_auth, show_logout_button
from components.session_manager import SessionManager
from components.api_client import APIClient, display_api_error, parseAgenticResponse
from components.constants import (
    COMPANY_TYPE_OPTIONS, INDUSTRY_OPTIONS, LOCATION_OPTIONS
)

# Page config
st.set_page_config(page_title="Agentic Analysis", page_icon="ü§ñ", layout="wide")

# Authentication
require_auth()

# Initialize session
SessionManager.init()

# Initialize API client
api_client = APIClient()

# Custom CSS for experimental badge
st.markdown("""
<style>
.experimental-badge {
    display: inline-block;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 4px 12px;
    border-radius: 12px;
    font-size: 0.75rem;
    font-weight: 600;
    margin-left: 10px;
    vertical-align: middle;
}
.phase-info {
    background-color: #f0f2f6;
    border-left: 4px solid #667eea;
    padding: 12px 16px;
    border-radius: 4px;
    margin-bottom: 20px;
}
.step-card {
    background-color: white;
    border: 1px solid #e0e0e0;
    border-radius: 8px;
    padding: 16px;
    margin-bottom: 12px;
}
.reflection-card {
    background-color: #f8f9fa;
    border-left: 4px solid #28a745;
    padding: 12px 16px;
    border-radius: 4px;
    margin-bottom: 12px;
}
.recommendation-box {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 20px;
    border-radius: 12px;
    margin-top: 20px;
}
</style>
""", unsafe_allow_html=True)

# Header
st.markdown('<h1>ü§ñ Agentic Analysis ‚ÑπÔ∏è <span class="experimental-badge">EXPERIMENTAL</span></h1>', unsafe_allow_html=True)
st.markdown("Advanced AI reasoning with transparent plan-execute-reflect cycles for deep compliance analysis.")
st.caption("‚ÑπÔ∏è **Agentic**: AI systems that can autonomously plan, execute, and reflect on tasks. This experimental feature uses multi-step reasoning to provide deeper analysis.")

# Experimental notice
st.markdown("""
<div class="phase-info">
    <strong>üß™ Experimental Feature - PHASE 1 Complete</strong><br>
    This is an experimental agentic AI engine that uses advanced reasoning patterns. 
    PHASE 1 structure is complete. PHASE 2 will implement full orchestrator logic.
</div>
""", unsafe_allow_html=True)

# ============================================================================
# SESSION STATE INITIALIZATION
# ============================================================================
if "agentic_results" not in st.session_state:
    st.session_state.agentic_results = None
if "agentic_form_data" not in st.session_state:
    st.session_state.agentic_form_data = {}

# ============================================================================
# EXAMPLE DATA
# ============================================================================
EXAMPLE_ENTITY = {
    "entity_name": "InnovateTech Solutions",
    "entity_type": "Private company (not traded publicly)",
    "locations": ["United States", "European Union countries"],
    "industry": "Technology and software",
    "employee_count": "150",
    "has_personal_data": True,
    "is_regulated": False,
    "previous_violations": "0"
}

EXAMPLE_TASK = {
    "task_description": "Implement GDPR Article 30 records of processing activities",
    "task_category": "DATA_PROTECTION",
    "priority": "High",
    "deadline": ""
}

# ============================================================================
# QUICK ACTIONS
# ============================================================================
col1, col2, col3 = st.columns([1, 1, 3])
with col1:
    if st.button("‚ö° Load Example", width='stretch'):
        st.session_state.agentic_form_data = {**EXAMPLE_ENTITY, **EXAMPLE_TASK}
        st.rerun()
with col2:
    if st.button("üîÑ Reset Form", width='stretch'):
        st.session_state.agentic_form_data = {}
        st.session_state.agentic_results = None
        st.rerun()

# ============================================================================
# MAIN FORM
# ============================================================================
with st.form("agentic_analysis_form", clear_on_submit=False):
    form_data = st.session_state.agentic_form_data
    
    st.markdown("## üè¢ Entity Information")
    
    col1, col2 = st.columns(2)
    
    with col1:
        entity_name = st.text_input(
            "Entity Name *",
            value=form_data.get("entity_name", ""),
            placeholder="Enter entity name",
            help="Name of the organization to analyze"
        )
        
        # Entity type
        entity_type_options = ["-- Please select --"] + [opt for opt in COMPANY_TYPE_OPTIONS if opt != "-- Please select --"]
        entity_type_index = entity_type_options.index(form_data.get("entity_type", entity_type_options[0])) if form_data.get("entity_type") in entity_type_options else 0
        entity_type = st.selectbox(
            "Type of Organization *",
            options=entity_type_options,
            index=entity_type_index
        )
        
        # Industry
        industry_options = ["-- Please select --"] + [opt for opt in INDUSTRY_OPTIONS if opt != "-- Please select --"]
        industry_index = industry_options.index(form_data.get("industry", industry_options[0])) if form_data.get("industry") in industry_options else 0
        industry = st.selectbox(
            "Industry *",
            options=industry_options,
            index=industry_index
        )
    
    with col2:
        employee_count = st.text_input(
            "Number of Employees",
            value=form_data.get("employee_count", ""),
            placeholder="e.g., 150",
            help="Approximate number of employees"
        )
        
        # Locations/Jurisdictions
        location_options = [loc for loc in LOCATION_OPTIONS if loc != "-- Please select --"]
        default_locations = form_data.get("locations", [])
        from components.ui_helpers import multiselect_with_select_all
        locations = multiselect_with_select_all(
            "Operating Locations *",
            options=location_options,
            default=default_locations,
            key="agentic_locations_multiselect",
            help="Select all jurisdictions where the entity operates"
        )
        
        # Additional context
        has_personal_data = st.checkbox(
            "Handles Personal Data",
            value=form_data.get("has_personal_data", True),
            help="Does the entity process personal or customer data?"
        )
    
    col3, col4 = st.columns(2)
    with col3:
        is_regulated = st.checkbox(
            "Directly Regulated Entity",
            value=form_data.get("is_regulated", False),
            help="Is the entity subject to direct regulatory oversight?"
        )
    with col4:
        previous_violations = st.text_input(
            "Previous Violations",
            value=form_data.get("previous_violations", "0"),
            placeholder="0",
            help="Number of previous compliance violations"
        )
    
    st.markdown("---")
    st.markdown("## üìã Task Information")
    
    task_description = st.text_area(
        "Task Description *",
        value=form_data.get("task_description", ""),
        placeholder="Describe the compliance task to analyze...",
        height=100,
        help="Detailed description of what needs to be analyzed"
    )
    
    col5, col6, col7 = st.columns(3)
    
    with col5:
        task_category_options = [
            "-- Please select --",
            "DATA_PROTECTION",
            "RISK_ASSESSMENT",
            "POLICY_REVIEW",
            "REGULATORY_FILING",
            "SECURITY_AUDIT",
            "INCIDENT_RESPONSE"
        ]
        task_category_index = task_category_options.index(form_data.get("task_category", task_category_options[0])) if form_data.get("task_category") in task_category_options else 0
        task_category = st.selectbox(
            "Task Category",
            options=task_category_options,
            index=task_category_index
        )
    
    with col6:
        priority_options = ["-- Please select --", "Low", "Medium", "High", "Critical"]
        priority_index = priority_options.index(form_data.get("priority", priority_options[0])) if form_data.get("priority") in priority_options else 0
        priority = st.selectbox(
            "Priority",
            options=priority_options,
            index=priority_index
        )
    
    with col7:
        deadline = st.date_input(
            "Deadline (Optional)",
            value=None,
            help="Target completion date"
        )
    
    st.markdown("---")
    
    # Advanced Options (collapsed by default)
    with st.expander("‚öôÔ∏è Advanced Options"):
        max_iterations = st.slider(
            "Max Reasoning Iterations",
            min_value=3,
            max_value=20,
            value=10,
            help="Maximum number of plan-execute-reflect cycles"
        )
    
    st.markdown("---")
    
    # Submit button
    submitted = st.form_submit_button("üöÄ Run Agentic Analysis", width='stretch', type="primary")
    
    if submitted:
        # Validation
        errors = []
        if not entity_name.strip():
            errors.append("Entity name is required")
        if entity_type == "-- Please select --":
            errors.append("Entity type is required")
        if industry == "-- Please select --":
            errors.append("Industry is required")
        if not locations:
            errors.append("At least one operating location is required")
        if not task_description.strip():
            errors.append("Task description is required")
        
        if errors:
            st.error("**Please fix the following errors:**\n\n" + "\n".join([f"‚Ä¢ {e}" for e in errors]))
        else:
            # Save form data
            st.session_state.agentic_form_data = {
                "entity_name": entity_name,
                "entity_type": entity_type,
                "locations": locations,
                "industry": industry,
                "employee_count": employee_count,
                "has_personal_data": has_personal_data,
                "is_regulated": is_regulated,
                "previous_violations": previous_violations,
                "task_description": task_description,
                "task_category": task_category,
                "priority": priority
            }
            
            # Prepare API request
            with st.spinner("ü§ñ Agentic AI is analyzing... This may take 60-90 seconds (planning, execution, and reflection phases)..."):
                request_payload = {
                    "entity": {
                        "entity_name": entity_name,
                        "entity_type": entity_type.replace("-- Please select --", "PRIVATE_COMPANY"),
                        "locations": locations,
                        "industry": industry.replace("-- Please select --", "TECHNOLOGY"),
                        "employee_count": int(employee_count) if employee_count.strip().isdigit() else None,
                        "has_personal_data": has_personal_data,
                        "is_regulated": is_regulated,
                        "previous_violations": int(previous_violations) if previous_violations.strip().isdigit() else 0
                    },
                    "task": {
                        "task_description": task_description,
                        "task_category": task_category if task_category != "-- Please select --" else "DATA_PROTECTION",
                        "priority": priority if priority != "-- Please select --" else "MEDIUM",
                        "deadline": deadline.isoformat() if deadline else None
                    },
                    "max_iterations": max_iterations
                }
                
                # Call API with 120s timeout for agentic analysis (can take 60-90 seconds)
                # Agentic analysis makes multiple LLM calls: planning + execution + reflection
                try:
                    response = api_client.post("/api/v1/agentic/analyze", request_payload, timeout=120)
                    
                    # Parse standardized agentic response
                    status, results, error, timestamp = parseAgenticResponse(response)
                    
                    if status == "completed" and results:
                        st.session_state.agentic_results = results
                        st.success(f"‚úÖ Analysis complete! (Completed at {timestamp or 'unknown'})")
                        st.rerun()
                    elif status == "timeout":
                        st.error(f"‚è±Ô∏è **Timeout**: {error or 'Analysis timed out after 120 seconds'}")
                        st.info("üí° **Tip**: Try reducing max iterations or simplifying the task description.")
                    elif status == "error":
                        st.error(f"‚ùå **Error**: {error or 'Unknown error occurred'}")
                        st.info("üí° **Troubleshooting**:\n1. Check that the backend is running\n2. Verify your network connection\n3. Try again with a simpler task")
                    else:
                        display_api_error(response)
                except Exception as e:
                    st.error(f"‚ùå **API Error**: {str(e)}")
                    st.info("üí° **Troubleshooting**:\n1. Check that the backend is running\n2. Verify your network connection\n3. Try again in a few moments")

# ============================================================================
# DISPLAY RESULTS
# ============================================================================
if st.session_state.agentic_results:
    results = st.session_state.agentic_results
    
    st.markdown("---")
    st.markdown("## üìä Analysis Results")
    
    # Status badge with better handling
    status = results.get("status", "unknown")
    if status == "placeholder":
        st.info("‚ö†Ô∏è **PLACEHOLDER RESPONSE**: This is a demo response showing the expected structure. Full implementation coming in PHASE 2.")
    elif status == "partial":
        st.warning("‚ö†Ô∏è **Partial Results**: Analysis completed but some steps may have failed. Review step outputs for details.")
    elif status == "error":
        st.error("‚ùå **Analysis Error**: The analysis encountered an error. Please try again or contact support.")
        if results.get("error"):
            st.code(results.get("error"), language="text")
        st.stop()
    
    # Tabs for different sections
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üìã Plan",
        "‚öôÔ∏è Step Outputs",
        "üîç Reflections",
        "üí° Recommendation",
        "üß† Memory & Metrics"
    ])
    
    # TAB 1: PLAN
    with tab1:
        st.markdown("### Execution Plan")
        st.markdown("The agentic AI generated the following strategic plan:")
        
        plan = results.get("plan", [])
        if plan and len(plan) > 0:
            for i, step in enumerate(plan, 1):
                with st.container():
                    expected_tools = step.get('expected_tools', []) or step.get('tools', [])
                    dependencies = step.get('dependencies', [])
                    st.markdown(f"""
                    <div class="step-card">
                        <h4>Step {i}: {step.get('description', 'N/A')}</h4>
                        <p><strong>Rationale:</strong> {step.get('rationale', 'N/A')}</p>
                        <p><strong>Expected Tools:</strong> {', '.join(expected_tools) if expected_tools else 'None'}</p>
                        <p><strong>Dependencies:</strong> {', '.join(dependencies) if dependencies else 'None'}</p>
                    </div>
                    """, unsafe_allow_html=True)
        else:
            st.info("""
            üìã **No Plan Generated**
            
            The execution plan will appear here once you run an analysis. 
            Click "Run Analysis" above to generate a strategic plan for your task.
            """)
    
    # TAB 2: STEP OUTPUTS
    with tab2:
        st.markdown("### Step Execution Results")
        st.markdown("Results from each step in the execution:")
        
        step_outputs = results.get("step_outputs", [])
        if step_outputs and len(step_outputs) > 0:
            for output in step_outputs:
                step_id = output.get("step_id", "unknown")
                status = output.get("status", "unknown")
                
                # Status icon
                status_icon = "‚úÖ" if status == "success" else "‚è≥" if status == "placeholder" else "‚ùå"
                
                with st.expander(f"{status_icon} {step_id.replace('_', ' ').title()}", expanded=False):
                    st.markdown(f"**Status:** `{status}`")
                    
                    st.markdown(f"**Output:**")
                    st.text(output.get("output", "No output"))
                    
                    # Display findings
                    findings = output.get("metrics", {}).get("findings", []) or output.get("findings", [])
                    if findings:
                        st.markdown(f"**üîç Key Findings:**")
                        for finding in findings:
                            st.markdown(f"- {finding}")
                    
                    # Display risks
                    risks = output.get("metrics", {}).get("risks", []) or output.get("risks", [])
                    if risks:
                        st.markdown(f"**‚ö†Ô∏è Risks Identified:**")
                        for risk in risks:
                            st.markdown(f"- {risk}")
                    
                    # Display confidence
                    confidence = output.get("metrics", {}).get("confidence", 0.0) or output.get("confidence", 0.0)
                    if confidence and confidence > 0:
                        st.metric("Confidence", f"{confidence:.2%}", 
                                help="Confidence score for this step's execution")
                    
                    tools_used = output.get("tools_used", [])
                    if tools_used:
                        st.markdown(f"**üîß Tools Used:** {', '.join(tools_used)}")
                    
                    metrics = output.get("metrics", {})
                    if metrics:
                        # Filter out findings, risks, confidence from raw metrics display
                        raw_metrics = {k: v for k, v in metrics.items() if k not in ["findings", "risks", "confidence"]}
                        if raw_metrics:
                            st.markdown(f"**üìä Metrics:**")
                            st.json(raw_metrics)
        else:
            st.info("""
            ‚öôÔ∏è **No Step Outputs Yet**
            
            Step execution results will appear here once you run an analysis.
            Each step's output, findings, risks, and confidence scores will be displayed.
            """)
    
    # TAB 3: REFLECTIONS
    with tab3:
        st.markdown("### Quality Reflections")
        st.markdown("AI critic's evaluation of each step:")
        
        reflections = results.get("reflections", [])
        for reflection in reflections:
            step_id = reflection.get("step_id", "unknown")
            quality_score = reflection.get("quality_score", 0.0)
            
            # Quality color
            if quality_score >= 0.8:
                quality_color = "#28a745"
            elif quality_score >= 0.6:
                quality_color = "#ffc107"
            else:
                quality_color = "#dc3545"
            
            st.markdown(f"""
            <div class="reflection-card" style="border-left-color: {quality_color};">
                <h4>{step_id.replace('_', ' ').title()}</h4>
                <p><strong>Quality Score:</strong> {quality_score:.2f} / 1.00</p>
            </div>
            """, unsafe_allow_html=True)
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                correctness_score = reflection.get("correctness_score", None)
                if correctness_score is not None:
                    st.metric("Correctness", f"{correctness_score:.2%}", 
                             "‚úÖ" if reflection.get("correctness") else "‚ùå")
                else:
                    st.metric("Correctness", "‚úÖ" if reflection.get("correctness") else "‚ùå")
            with col2:
                completeness_score = reflection.get("completeness_score", None)
                if completeness_score is not None:
                    st.metric("Completeness", f"{completeness_score:.2%}",
                             "‚úÖ" if reflection.get("completeness") else "‚ùå")
                else:
                    st.metric("Completeness", "‚úÖ" if reflection.get("completeness") else "‚ùå")
            with col3:
                st.metric("Confidence", f"{reflection.get('confidence', 0.0):.2%}")
            with col4:
                st.metric("Quality Score", f"{reflection.get('quality_score', 0.0):.2%}")
            
            issues = reflection.get("issues", [])
            if issues:
                st.markdown("**‚ö†Ô∏è Issues Identified:**")
                for issue in issues:
                    st.markdown(f"- {issue}")
            
            suggestions = reflection.get("suggestions", [])
            if suggestions:
                st.markdown("**üí° Suggestions:**")
                for suggestion in suggestions:
                    st.markdown(f"- {suggestion}")
            
            st.markdown("---")
        
        if not reflections:
            st.info("""
            üîç **No Reflections Yet**
            
            Quality reflections will appear here once you run an analysis.
            The AI critic evaluates each step for correctness, completeness, and quality.
            """)
    
    # TAB 4: RECOMMENDATION
    with tab4:
        st.markdown("### Final Recommendation")
        
        final_recommendation = results.get("final_recommendation", "")
        confidence_score = results.get("confidence_score", 0.0)
        
        if not final_recommendation or final_recommendation == "No recommendation available":
            st.info("""
            üí° **No Recommendation Yet**
            
            The final recommendation will appear here once you run an analysis.
            This is the AI's comprehensive guidance based on all step analyses.
            """)
            st.stop()
        
        st.markdown(f"""
        <div class="recommendation-box">
            <h3>üéØ AI Recommendation</h3>
            <p style="font-size: 1.1rem; line-height: 1.6;">{final_recommendation}</p>
            <br>
            <p><strong>Confidence Score:</strong> {confidence_score:.2%}</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Download option
        st.markdown("---")
        col1, col2 = st.columns([1, 3])
        with col1:
            # Prepare download data
            download_data = {
                "entity": form_data.get("entity_name", "Unknown"),
                "task": form_data.get("task_description", ""),
                "timestamp": datetime.now().isoformat(),
                "results": results
            }
            st.download_button(
                label="üì• Download Full Report",
                data=json.dumps(download_data, indent=2),
                file_name=f"agentic_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                width='stretch'
            )
    
    # TAB 5: MEMORY & METRICS
    with tab5:
        st.markdown("### Execution Metrics")
        
        metrics = results.get("execution_metrics", {})
        
        if metrics:
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                total_steps = metrics.get("total_steps", 0)
                st.metric("Total Steps", total_steps if total_steps > 0 else "N/A", 
                         help="Number of steps in the execution plan")
            with col2:
                duration = metrics.get("duration_seconds", 0)
                if duration > 0:
                    st.metric("Duration", f"{duration:.2f}s", 
                             help="Total execution time in seconds")
                else:
                    st.metric("Duration", "N/A", help="Execution time not available")
            with col3:
                status = metrics.get("status", "unknown")
                st.metric("Status", status.upper() if status != "unknown" else "N/A",
                         help="Overall execution status")
            with col4:
                success_rate = metrics.get("success_rate", 0.0)
                if success_rate > 0:
                    st.metric("Success Rate", f"{success_rate:.1f}%",
                             help="Percentage of steps that completed successfully")
                else:
                    st.metric("Success Rate", "N/A", help="Success rate not calculated")
        else:
            st.info("üìä **No Metrics Available**: Execution metrics will appear here after running an analysis.")
        
        # Tool Usage Visualization
        st.markdown("---")
        st.markdown("### üîß Tool Usage")
        
        # Collect tool usage from all steps
        all_tools_used = []
        step_outputs_list = results.get("step_outputs", [])
        for output in step_outputs_list:
            tools = output.get("tools_used", [])
            if tools:
                all_tools_used.extend(tools)
        
        if all_tools_used:
            from collections import Counter
            tool_counts = Counter(all_tools_used)
            
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**Tool Call Frequency:**")
                for tool, count in tool_counts.most_common():
                    st.markdown(f"- {tool}: {count} time{'s' if count > 1 else ''}")
            
            with col2:
                # Simple bar chart visualization
                import pandas as pd
                df = pd.DataFrame(list(tool_counts.items()), columns=["Tool", "Count"])
                st.bar_chart(df.set_index("Tool"))
        else:
            st.info("üîß **No Tools Used**: This analysis didn't require any tools. Tools will appear here when the agent uses entity, calendar, task, or HTTP tools.")
        
        # Reasoning Metrics
        st.markdown("---")
        st.markdown("### üß† Reasoning Metrics")
        
        # Check for multi-pass reasoning indicators
        reasoning_passes_total = 0
        step_outputs_list = results.get("step_outputs", [])
        for output in step_outputs_list:
            metrics_data = output.get("metrics", {})
            if "reasoning_passes" in metrics_data:
                reasoning_passes_total += metrics_data["reasoning_passes"]
        
        if reasoning_passes_total > 0:
            st.success(f"‚úÖ Multi-pass reasoning was used ({reasoning_passes_total} total passes)")
            st.info("Complex steps were analyzed using multiple reasoning passes for improved accuracy.")
        else:
            st.info("üß† **Standard Reasoning**: All steps used single-pass reasoning. Multi-pass reasoning activates automatically for complex steps.")
        
        st.markdown("---")
        st.markdown("### üìä Detailed Metrics")
        
        # Success/Failure breakdown
        successful_steps = metrics.get("successful_steps")
        failed_steps = metrics.get("failed_steps")
        if successful_steps is not None or failed_steps is not None:
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Successful Steps", successful_steps if successful_steps is not None else "N/A",
                         help="Number of steps that completed successfully")
            with col2:
                st.metric("Failed Steps", failed_steps if failed_steps is not None else "N/A",
                         help="Number of steps that failed during execution")
        
        # Average step time
        avg_step_time = metrics.get("average_step_time")
        if avg_step_time and avg_step_time > 0:
            st.metric("Average Step Time", f"{avg_step_time:.3f}s",
                     help="Average time taken per step in seconds")
        elif metrics:
            st.info("‚è±Ô∏è Step timing metrics will appear here after analysis completes.")
        
        st.markdown("---")
        st.markdown("### üß† Memory Updates (PHASE 3)")
        
        st.info("""
        **Coming in PHASE 3:**
        - Episodic memory of this analysis session
        - Semantic knowledge learned from the analysis
        - Historical pattern recognition
        - Cross-session insights
        
        The agentic engine will remember insights from this analysis and apply
        them to future tasks.
        """)
        
        # Raw metrics
        with st.expander("üîç View Raw Metrics"):
            st.json(metrics)

# ============================================================================
# SIDEBAR INFO
# ============================================================================
with st.sidebar:
    show_logout_button()
    st.markdown("### ü§ñ About Agentic Analysis")
    st.markdown("""
    This experimental feature uses an advanced agentic AI architecture with:
    
    **üéØ Planning Phase**
    - Strategic task decomposition
    - Tool selection
    - Dependency mapping
    
    **‚öôÔ∏è Execution Phase**
    - Tool-augmented reasoning
    - Data gathering
    - Progressive analysis
    
    **üîç Reflection Phase**
    - Quality assessment
    - Correctness validation
    - Iterative improvement
    
    **üß† Memory Phase (PHASE 3)**
    - Episodic memory
    - Semantic learning
    - Pattern recognition
    """)
    
    st.markdown("---")
    st.markdown("### üìö Development Status")
    st.success("‚úÖ PHASE 1: Structure Complete")
    st.info("‚è≥ PHASE 2: Logic Implementation")
    st.info("‚è≥ PHASE 3: Memory & Learning")

